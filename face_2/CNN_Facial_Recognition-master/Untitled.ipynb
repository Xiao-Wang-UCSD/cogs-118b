{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-b82af2e3e6b5>:128: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "prediction shape=\n",
      "(?, 15)\n",
      "logits shape=\n",
      "(?, 15)\n",
      "WARNING:tensorflow:From <ipython-input-20-b82af2e3e6b5>:140: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch 1/200, loss:367459.65625 Test Accuracy: 0.06666667\n",
      "Epoch 2/200, loss:282834.1875 Test Accuracy: 0.033333335\n",
      "Epoch 3/200, loss:229473.90625 Test Accuracy: 0.1\n",
      "Epoch 4/200, loss:215840.84375 Test Accuracy: 0.16666667\n",
      "Epoch 5/200, loss:184066.625 Test Accuracy: 0.13333334\n",
      "Epoch 6/200, loss:173968.171875 Test Accuracy: 0.06666667\n",
      "Epoch 7/200, loss:132778.03125 Test Accuracy: 0.06666667\n",
      "Epoch 8/200, loss:143282.625 Test Accuracy: 0.13333334\n",
      "Epoch 9/200, loss:127596.1484375 Test Accuracy: 0.2\n",
      "Epoch 10/200, loss:109986.3828125 Test Accuracy: 0.033333335\n",
      "Epoch 11/200, loss:125137.6875 Test Accuracy: 0.2\n",
      "Epoch 12/200, loss:118506.1796875 Test Accuracy: 0.1\n",
      "Epoch 13/200, loss:101381.8828125 Test Accuracy: 0.1\n",
      "Epoch 14/200, loss:86170.8828125 Test Accuracy: 0.2\n",
      "Epoch 15/200, loss:82938.0546875 Test Accuracy: 0.2\n",
      "Epoch 16/200, loss:75481.2734375 Test Accuracy: 0.1\n",
      "Epoch 17/200, loss:78673.359375 Test Accuracy: 0.4\n",
      "Epoch 18/200, loss:66119.875 Test Accuracy: 0.23333333\n",
      "Epoch 19/200, loss:63319.171875 Test Accuracy: 0.23333333\n",
      "Epoch 20/200, loss:64326.23046875 Test Accuracy: 0.43333334\n",
      "Epoch 21/200, loss:61512.546875 Test Accuracy: 0.2\n",
      "Epoch 22/200, loss:52171.44921875 Test Accuracy: 0.26666668\n",
      "Epoch 23/200, loss:54917.44921875 Test Accuracy: 0.33333334\n",
      "Epoch 24/200, loss:53840.6484375 Test Accuracy: 0.36666667\n",
      "Epoch 25/200, loss:38479.6484375 Test Accuracy: 0.16666667\n",
      "Epoch 26/200, loss:41592.9453125 Test Accuracy: 0.4\n",
      "Epoch 27/200, loss:37866.515625 Test Accuracy: 0.3\n",
      "Epoch 28/200, loss:37875.81640625 Test Accuracy: 0.33333334\n",
      "Epoch 29/200, loss:34586.65625 Test Accuracy: 0.46666667\n",
      "Epoch 30/200, loss:30868.103515625 Test Accuracy: 0.46666667\n",
      "Epoch 31/200, loss:36979.046875 Test Accuracy: 0.5\n",
      "Epoch 32/200, loss:27458.3046875 Test Accuracy: 0.46666667\n",
      "Epoch 33/200, loss:27407.48828125 Test Accuracy: 0.43333334\n",
      "Epoch 34/200, loss:23717.625 Test Accuracy: 0.43333334\n",
      "Epoch 35/200, loss:21717.75390625 Test Accuracy: 0.4\n",
      "Epoch 36/200, loss:24169.26171875 Test Accuracy: 0.46666667\n",
      "Epoch 37/200, loss:19091.29296875 Test Accuracy: 0.53333336\n",
      "Epoch 38/200, loss:16416.24609375 Test Accuracy: 0.6333333\n",
      "Epoch 39/200, loss:17199.6484375 Test Accuracy: 0.56666666\n",
      "Epoch 40/200, loss:24042.185546875 Test Accuracy: 0.43333334\n",
      "Epoch 41/200, loss:12601.6357421875 Test Accuracy: 0.5\n",
      "Epoch 42/200, loss:18155.318359375 Test Accuracy: 0.53333336\n",
      "Epoch 43/200, loss:16400.623046875 Test Accuracy: 0.6333333\n",
      "Epoch 44/200, loss:10033.2509765625 Test Accuracy: 0.5\n",
      "Epoch 45/200, loss:12836.7373046875 Test Accuracy: 0.6333333\n",
      "Epoch 46/200, loss:11212.6484375 Test Accuracy: 0.5\n",
      "Epoch 47/200, loss:12658.0068359375 Test Accuracy: 0.56666666\n",
      "Epoch 48/200, loss:8785.1083984375 Test Accuracy: 0.5\n",
      "Epoch 49/200, loss:6570.61669921875 Test Accuracy: 0.6666667\n",
      "Epoch 50/200, loss:9532.1083984375 Test Accuracy: 0.5\n",
      "Epoch 51/200, loss:7497.86669921875 Test Accuracy: 0.6\n",
      "Epoch 52/200, loss:5721.4384765625 Test Accuracy: 0.6333333\n",
      "Epoch 53/200, loss:9662.0263671875 Test Accuracy: 0.76666665\n",
      "Epoch 54/200, loss:6095.93408203125 Test Accuracy: 0.6333333\n",
      "Epoch 55/200, loss:6465.98486328125 Test Accuracy: 0.6666667\n",
      "Epoch 56/200, loss:4926.0224609375 Test Accuracy: 0.76666665\n",
      "Epoch 57/200, loss:5997.37109375 Test Accuracy: 0.73333335\n",
      "Epoch 58/200, loss:3946.2841796875 Test Accuracy: 0.6666667\n",
      "Epoch 59/200, loss:4295.38427734375 Test Accuracy: 0.7\n",
      "Epoch 60/200, loss:6429.88134765625 Test Accuracy: 0.7\n",
      "Epoch 61/200, loss:6161.00830078125 Test Accuracy: 0.8\n",
      "Epoch 62/200, loss:4042.64990234375 Test Accuracy: 0.76666665\n",
      "Epoch 63/200, loss:3094.47412109375 Test Accuracy: 0.6666667\n",
      "Epoch 64/200, loss:2808.110107421875 Test Accuracy: 0.56666666\n",
      "Epoch 65/200, loss:4541.96142578125 Test Accuracy: 0.6333333\n",
      "Epoch 66/200, loss:4774.349609375 Test Accuracy: 0.7\n",
      "Epoch 67/200, loss:3807.53759765625 Test Accuracy: 0.6333333\n",
      "Epoch 68/200, loss:3652.332275390625 Test Accuracy: 0.8\n",
      "Epoch 69/200, loss:3765.314697265625 Test Accuracy: 0.76666665\n",
      "Epoch 70/200, loss:4171.794921875 Test Accuracy: 0.76666665\n",
      "Epoch 71/200, loss:3204.96240234375 Test Accuracy: 0.6333333\n",
      "Epoch 72/200, loss:3173.34912109375 Test Accuracy: 0.73333335\n",
      "Epoch 73/200, loss:2225.897705078125 Test Accuracy: 0.73333335\n",
      "Epoch 74/200, loss:1475.56640625 Test Accuracy: 0.76666665\n",
      "Epoch 75/200, loss:1683.2125244140625 Test Accuracy: 0.7\n",
      "Epoch 76/200, loss:1177.4132080078125 Test Accuracy: 0.76666665\n",
      "Epoch 77/200, loss:978.0215454101562 Test Accuracy: 0.6666667\n",
      "Epoch 78/200, loss:2298.43701171875 Test Accuracy: 0.76666665\n",
      "Epoch 79/200, loss:2803.745849609375 Test Accuracy: 0.73333335\n",
      "Epoch 80/200, loss:2774.129638671875 Test Accuracy: 0.8\n",
      "Epoch 81/200, loss:833.5701904296875 Test Accuracy: 0.6666667\n",
      "Epoch 82/200, loss:1051.08837890625 Test Accuracy: 0.8\n",
      "Epoch 83/200, loss:1578.2998046875 Test Accuracy: 0.73333335\n",
      "Epoch 84/200, loss:512.9482421875 Test Accuracy: 0.76666665\n",
      "Epoch 85/200, loss:1090.8125 Test Accuracy: 0.73333335\n",
      "Epoch 86/200, loss:129.41845703125 Test Accuracy: 0.8\n",
      "Epoch 87/200, loss:1919.9803466796875 Test Accuracy: 0.8333333\n",
      "Epoch 88/200, loss:1336.441650390625 Test Accuracy: 0.73333335\n",
      "Epoch 89/200, loss:1602.7572021484375 Test Accuracy: 0.76666665\n",
      "Epoch 90/200, loss:1718.35302734375 Test Accuracy: 0.8\n",
      "Epoch 91/200, loss:2385.0185546875 Test Accuracy: 0.8\n",
      "Epoch 92/200, loss:1391.796630859375 Test Accuracy: 0.8\n",
      "Epoch 93/200, loss:1273.0859375 Test Accuracy: 0.7\n",
      "Epoch 94/200, loss:1181.5147705078125 Test Accuracy: 0.73333335\n",
      "Epoch 95/200, loss:1233.3729248046875 Test Accuracy: 0.73333335\n",
      "Epoch 96/200, loss:429.1009216308594 Test Accuracy: 0.73333335\n",
      "Epoch 97/200, loss:1294.87890625 Test Accuracy: 0.76666665\n",
      "Epoch 98/200, loss:518.2359619140625 Test Accuracy: 0.6666667\n",
      "Epoch 99/200, loss:820.2394409179688 Test Accuracy: 0.73333335\n",
      "Epoch 100/200, loss:651.2509155273438 Test Accuracy: 0.8\n",
      "Epoch 101/200, loss:1094.3807373046875 Test Accuracy: 0.76666665\n",
      "Epoch 102/200, loss:800.001220703125 Test Accuracy: 0.8\n",
      "Epoch 103/200, loss:819.9625854492188 Test Accuracy: 0.73333335\n",
      "Epoch 104/200, loss:54.375579833984375 Test Accuracy: 0.76666665\n",
      "Epoch 105/200, loss:611.6700439453125 Test Accuracy: 0.73333335\n",
      "Epoch 106/200, loss:108.98379516601562 Test Accuracy: 0.8\n",
      "Epoch 107/200, loss:1108.29833984375 Test Accuracy: 0.7\n",
      "Epoch 108/200, loss:1099.7025146484375 Test Accuracy: 0.8\n",
      "Epoch 109/200, loss:590.3744506835938 Test Accuracy: 0.8\n",
      "Epoch 110/200, loss:825.1139526367188 Test Accuracy: 0.8333333\n",
      "Epoch 111/200, loss:523.5315551757812 Test Accuracy: 0.8333333\n",
      "Epoch 112/200, loss:1072.4276123046875 Test Accuracy: 0.8\n",
      "Epoch 113/200, loss:377.99127197265625 Test Accuracy: 0.8\n",
      "Epoch 114/200, loss:783.1788330078125 Test Accuracy: 0.8666667\n",
      "Epoch 115/200, loss:31.235647201538086 Test Accuracy: 0.8333333\n",
      "Epoch 116/200, loss:689.4892578125 Test Accuracy: 0.76666665\n",
      "Epoch 117/200, loss:515.9257202148438 Test Accuracy: 0.8666667\n",
      "Epoch 118/200, loss:1065.8485107421875 Test Accuracy: 0.76666665\n",
      "Epoch 119/200, loss:137.14305114746094 Test Accuracy: 0.8333333\n",
      "Epoch 120/200, loss:1110.9613037109375 Test Accuracy: 0.8666667\n",
      "Epoch 121/200, loss:569.2388916015625 Test Accuracy: 0.8666667\n",
      "Epoch 122/200, loss:933.5288696289062 Test Accuracy: 0.9\n",
      "Epoch 123/200, loss:70.55144500732422 Test Accuracy: 0.8666667\n",
      "Epoch 124/200, loss:116.78292846679688 Test Accuracy: 0.8333333\n",
      "Epoch 125/200, loss:992.5657348632812 Test Accuracy: 0.8\n",
      "Epoch 126/200, loss:496.3467712402344 Test Accuracy: 0.76666665\n",
      "Epoch 127/200, loss:1438.4598388671875 Test Accuracy: 0.8666667\n",
      "Epoch 128/200, loss:172.57205200195312 Test Accuracy: 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/200, loss:475.6197814941406 Test Accuracy: 0.8333333\n",
      "Epoch 130/200, loss:666.5857543945312 Test Accuracy: 0.8666667\n",
      "Epoch 131/200, loss:925.7435913085938 Test Accuracy: 0.8\n",
      "Epoch 132/200, loss:576.4818115234375 Test Accuracy: 0.76666665\n",
      "Epoch 133/200, loss:378.68109130859375 Test Accuracy: 0.8\n",
      "Epoch 134/200, loss:414.8340148925781 Test Accuracy: 0.8\n",
      "Epoch 135/200, loss:550.9185791015625 Test Accuracy: 0.8333333\n",
      "Epoch 136/200, loss:333.0078125 Test Accuracy: 0.8333333\n",
      "Epoch 137/200, loss:136.67616271972656 Test Accuracy: 0.8\n",
      "Epoch 138/200, loss:0.0 Test Accuracy: 0.8333333\n",
      "Epoch 139/200, loss:315.5169982910156 Test Accuracy: 0.8333333\n",
      "Epoch 140/200, loss:358.98663330078125 Test Accuracy: 0.8333333\n",
      "Epoch 141/200, loss:426.93408203125 Test Accuracy: 0.76666665\n",
      "Epoch 142/200, loss:923.8621826171875 Test Accuracy: 0.8666667\n",
      "Epoch 143/200, loss:422.0325927734375 Test Accuracy: 0.9\n",
      "Epoch 144/200, loss:1476.1490478515625 Test Accuracy: 0.8\n",
      "Epoch 145/200, loss:218.72169494628906 Test Accuracy: 0.8333333\n",
      "Epoch 146/200, loss:468.1221618652344 Test Accuracy: 0.8333333\n",
      "Epoch 147/200, loss:127.19149017333984 Test Accuracy: 0.93333334\n",
      "Epoch 148/200, loss:234.14340209960938 Test Accuracy: 0.8\n",
      "Epoch 149/200, loss:26.590566635131836 Test Accuracy: 0.8666667\n",
      "Epoch 150/200, loss:56.95648193359375 Test Accuracy: 0.8666667\n",
      "Epoch 151/200, loss:0.0 Test Accuracy: 0.9\n",
      "Epoch 152/200, loss:402.786865234375 Test Accuracy: 0.76666665\n",
      "Epoch 153/200, loss:65.54768371582031 Test Accuracy: 0.8333333\n",
      "Epoch 154/200, loss:270.56597900390625 Test Accuracy: 0.8\n",
      "Epoch 155/200, loss:222.78819274902344 Test Accuracy: 0.93333334\n",
      "Epoch 156/200, loss:226.44711303710938 Test Accuracy: 0.8333333\n",
      "Epoch 157/200, loss:22.514583587646484 Test Accuracy: 0.8666667\n",
      "Epoch 158/200, loss:168.91990661621094 Test Accuracy: 0.8\n",
      "Epoch 159/200, loss:286.4166564941406 Test Accuracy: 0.8666667\n",
      "Epoch 160/200, loss:375.56256103515625 Test Accuracy: 0.8333333\n",
      "Epoch 161/200, loss:537.6236572265625 Test Accuracy: 0.8333333\n",
      "Epoch 162/200, loss:195.5321807861328 Test Accuracy: 0.8666667\n",
      "Epoch 163/200, loss:505.68853759765625 Test Accuracy: 0.8333333\n",
      "Epoch 164/200, loss:209.2810516357422 Test Accuracy: 0.8333333\n",
      "Epoch 165/200, loss:128.8389129638672 Test Accuracy: 0.8666667\n",
      "Epoch 166/200, loss:140.40411376953125 Test Accuracy: 0.8666667\n",
      "Epoch 167/200, loss:561.7698974609375 Test Accuracy: 0.8666667\n",
      "Epoch 168/200, loss:397.91876220703125 Test Accuracy: 0.8\n",
      "Epoch 169/200, loss:571.6669921875 Test Accuracy: 0.8333333\n",
      "Epoch 170/200, loss:33.72013854980469 Test Accuracy: 0.9\n",
      "Epoch 171/200, loss:0.0 Test Accuracy: 0.8333333\n",
      "Epoch 172/200, loss:289.9047546386719 Test Accuracy: 0.8\n",
      "Epoch 173/200, loss:3.929050922393799 Test Accuracy: 0.8333333\n",
      "Epoch 174/200, loss:0.0 Test Accuracy: 0.8666667\n",
      "Epoch 175/200, loss:162.53970336914062 Test Accuracy: 0.8666667\n",
      "Epoch 176/200, loss:159.03854370117188 Test Accuracy: 0.8\n",
      "Epoch 177/200, loss:111.94878387451172 Test Accuracy: 0.8\n",
      "Epoch 178/200, loss:128.60543823242188 Test Accuracy: 0.8333333\n",
      "Epoch 179/200, loss:112.3857650756836 Test Accuracy: 0.8333333\n",
      "Epoch 180/200, loss:112.64490509033203 Test Accuracy: 0.8333333\n",
      "Epoch 181/200, loss:0.0 Test Accuracy: 0.8333333\n",
      "Epoch 182/200, loss:266.59466552734375 Test Accuracy: 0.8666667\n",
      "Epoch 183/200, loss:107.20352935791016 Test Accuracy: 0.8666667\n",
      "Epoch 184/200, loss:0.0 Test Accuracy: 0.8333333\n",
      "Epoch 185/200, loss:124.44976806640625 Test Accuracy: 0.9\n",
      "Epoch 186/200, loss:307.7391052246094 Test Accuracy: 0.8333333\n",
      "Epoch 187/200, loss:150.80178833007812 Test Accuracy: 0.8666667\n",
      "Epoch 188/200, loss:258.3855285644531 Test Accuracy: 0.9\n",
      "Epoch 189/200, loss:0.0 Test Accuracy: 0.8666667\n",
      "Epoch 190/200, loss:264.708740234375 Test Accuracy: 0.9\n",
      "Epoch 191/200, loss:546.8761596679688 Test Accuracy: 0.9\n",
      "Epoch 192/200, loss:0.0 Test Accuracy: 0.8666667\n",
      "Epoch 193/200, loss:0.0 Test Accuracy: 0.8666667\n",
      "Epoch 194/200, loss:25.656307220458984 Test Accuracy: 0.9\n",
      "Epoch 195/200, loss:192.38992309570312 Test Accuracy: 0.8\n",
      "Epoch 196/200, loss:4.446759223937988 Test Accuracy: 0.8333333\n",
      "Epoch 197/200, loss:117.68738555908203 Test Accuracy: 0.9\n",
      "Epoch 198/200, loss:118.21823120117188 Test Accuracy: 0.9\n",
      "Epoch 199/200, loss:0.0 Test Accuracy: 0.8666667\n",
      "Epoch 200/200, loss:88.88946533203125 Test Accuracy: 0.8666667\n",
      "Accuracy: 0.8\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b82af2e3e6b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/results/accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmyfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0mwr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mwr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macclist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/results/loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmyfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import os\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "\n",
    "imsize=56#define how big the square image should be along a side, e.g. imsize=100 means that images will be converted to 100x100 images, this value should be divisible by 4\n",
    "num_epochs=200\n",
    "\n",
    "\n",
    "########################################################################################################################################\n",
    "#Obtain all images from the data directory, Yale Face Database obtained from http://vision.ucsd.edu/content/yale-face-database\n",
    "datadirectory=os.getcwd()+'/data/'\n",
    "allimgnames=os.listdir(datadirectory)\n",
    "\n",
    "allimgnamesdict=dict()\n",
    "for i in allimgnames:\n",
    "    subjnum=int(i[7:9])\n",
    "    if subjnum in allimgnamesdict.keys():\n",
    "        allimgnamesdict[subjnum].append(i)\n",
    "    else:\n",
    "        allimgnamesdict[subjnum]=list()\n",
    "        allimgnamesdict[subjnum].append(i)\n",
    "n_classes=len(allimgnamesdict)\n",
    "########################################################################################################################################\n",
    "\n",
    "train_set_names=list()\n",
    "train_set_labels=list()\n",
    "test_set_names=list()\n",
    "test_set_labels=list()\n",
    "\n",
    "for i in  allimgnamesdict:\n",
    "    random.shuffle(allimgnamesdict[i])\n",
    "    hm_test=int(0.2*len(allimgnamesdict[i]))#how many examples to take for the test set, here we use 20% of data for test and 80% for training\n",
    "    test_set_names=test_set_names+allimgnamesdict[i][0:hm_test]\n",
    "    test_set_labels=test_set_labels+[int(i)]*hm_test\n",
    "    train_set_names=train_set_names+allimgnamesdict[i][hm_test:]\n",
    "    train_set_labels=train_set_labels+[int(i)]*(len(allimgnamesdict[i])-hm_test)\n",
    "\n",
    "##################################################\n",
    "#shuffle the training and testing sets \n",
    "combinetrain=list(zip(train_set_names,train_set_labels))\n",
    "combinetest=list(zip(test_set_names,test_set_labels))\n",
    "\n",
    "random.shuffle(combinetrain)\n",
    "random.shuffle(combinetest)\n",
    "\n",
    "train_set_names[:],train_set_labels[:]=zip(*combinetrain)\n",
    "test_set_names[:],test_set_labels[:]=zip(*combinetest)\n",
    "##################################################\n",
    "\n",
    "'''\n",
    "print allimgtensor\n",
    "print type(allimgtensor)\n",
    "print allimglabels\n",
    "print type(allimaglabelstensor)\n",
    "'''\n",
    "\n",
    "testarray=np.zeros((len(test_set_names),imsize*imsize))\n",
    "testlabels=np.zeros((len(test_set_names),n_classes))\n",
    "counter=0\n",
    "for i in test_set_names:\n",
    "    testlabels[counter,int(test_set_names[counter][7:9])-1]=1#labels as one hot\n",
    "    im=Image.open(datadirectory+i)\n",
    "    im=im.resize((imsize,imsize),Image.NEAREST)\n",
    "    im=np.asarray(im)/255.0\n",
    "    testarray[counter,:]=im.reshape((imsize*imsize,))\n",
    "    counter+=1\n",
    "    '''\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "trainarray=np.zeros((len(train_set_names),imsize*imsize))\n",
    "trainlabels=np.zeros((len(train_set_labels),n_classes))\n",
    "counter=0\n",
    "for i in train_set_names:\n",
    "    trainlabels[counter,int(train_set_names[counter][7:9])-1]=1#labels as one hot\n",
    "    im=Image.open(datadirectory+i)\n",
    "    im=im.resize((imsize,imsize),Image.NEAREST)\n",
    "    im=np.asarray(im)/255.0\n",
    "    trainarray[counter,:]=im.reshape((imsize*imsize,))\n",
    "    counter+=1\n",
    "\n",
    "########################################################################################################################################\n",
    "x = tf.placeholder('float', [None, imsize*imsize])\n",
    "y = tf.placeholder('float',[None,n_classes])\n",
    "\n",
    "keep_rate = 0.8#0.8\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def maxpool2d(x):\n",
    "    #                        size of window         movement of window\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "\n",
    "\n",
    "def convolutional_neural_network(x):\n",
    "    weights = {'W_conv1':tf.Variable(tf.random_normal([5,5,1,32])),\n",
    "               'W_conv2':tf.Variable(tf.random_normal([5,5,32,64])),\n",
    "               'W_fc':tf.Variable(tf.random_normal([int(imsize/4)*int(imsize/4)*64,1024])),#imsize/4 because each max pool has a stride of 2, so it reduces dimensionality by 2 twice or 1/2^2\n",
    "               'out':tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "    biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n",
    "               'b_conv2':tf.Variable(tf.random_normal([64])),\n",
    "               'b_fc':tf.Variable(tf.random_normal([1024])),\n",
    "               'out':tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "    x = tf.reshape(x, shape=[-1, imsize, imsize, 1])\n",
    "\n",
    "    conv1 = tf.nn.relu(conv2d(x, weights['W_conv1']) + biases['b_conv1'])\n",
    "    conv1 = maxpool2d(conv1)\n",
    "    \n",
    "    conv2 = tf.nn.relu(conv2d(conv1, weights['W_conv2']) + biases['b_conv2'])\n",
    "    conv2 = maxpool2d(conv2)\n",
    "\n",
    "    fc = tf.reshape(conv2,[-1, int(imsize/4)*int(imsize/4)*64])#imsize/4 because each max pool has a stride of 2, so it reduces dimensionality by 2 twice or 1/2^2\n",
    "    fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n",
    "    fc = tf.nn.dropout(fc, keep_rate)\n",
    "\n",
    "    output = tf.matmul(fc, weights['out'])+biases['out']\n",
    "\n",
    "    return output\n",
    "\n",
    "def train_neural_network(x):\n",
    "    prediction = convolutional_neural_network(x)\n",
    "    print('prediction shape=')\n",
    "    print(prediction.get_shape())\n",
    "    print('logits shape=')\n",
    "    print(y.get_shape())\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        #sess.run(tf.initialize_all_variables())\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        \n",
    "        acclist=list()\n",
    "        losslist=list()\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_loss = 0\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: trainarray, y: trainlabels})\n",
    "            epoch_loss += c\n",
    "            correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "            acclist.append(accuracy.eval({x:testarray, y:testlabels}))\n",
    "            losslist.append(epoch_loss)\n",
    "            print('Epoch '+ str(epoch+1) + '/'+str(num_epochs)+','+' loss:'+str(epoch_loss),'Test Accuracy:',accuracy.eval({x:testarray, y:testlabels}))\n",
    "        \n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:',accuracy.eval({x:testarray, y:testlabels}))\n",
    "        return acclist,losslist\n",
    "\n",
    "acclist,losslist=train_neural_network(x)\n",
    "\n",
    "with open(os.getcwd()+'/results/accuracy', 'wb') as myfile:\n",
    "    wr = csv.writer(myfile)\n",
    "    wr.writerow(acclist)\n",
    "\n",
    "with open(os.getcwd()+'/results/loss', 'wb') as myfile:\n",
    "    wr = csv.writer(myfile)\n",
    "    wr.writerow(losslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadirectory=os.getcwd()+'/data'\n",
    "allimgnames=os.listdir(datadirectory)\n",
    "allimgnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "allimgnamesdict=dict()\n",
    "for i in allimgnames:\n",
    "    subjnum=int(i[7:9])\n",
    "    if subjnum in allimgnamesdict.keys():\n",
    "        allimgnamesdict[subjnum].append(i)\n",
    "    else:\n",
    "        allimgnamesdict[subjnum]=list()\n",
    "        allimgnamesdict[subjnum].append(i)\n",
    "n_classes=len(allimgnamesdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
