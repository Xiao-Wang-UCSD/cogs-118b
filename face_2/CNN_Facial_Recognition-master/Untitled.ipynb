{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import os\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "\n",
    "\n",
    "imsize=100#define how big the square image should be along a side, e.g. imsize=100 means that images will be converted to 100x100 images, this value should be divisible by 4\n",
    "num_epochs=100\n",
    "\n",
    "\n",
    "########################################################################################################################################\n",
    "#Obtain all images from the data directory, Yale Face Database obtained from http://vision.ucsd.edu/content/yale-face-database\n",
    "datadirectory=os.getcwd()+'/data/'\n",
    "allimgnames=os.listdir(datadirectory)\n",
    "\n",
    "allimgnamesdict=dict()\n",
    "for i in allimgnames:\n",
    "    subjnum=int(i[7:9])\n",
    "    if subjnum in allimgnamesdict.keys():\n",
    "        allimgnamesdict[subjnum].append(i)\n",
    "    else:\n",
    "        allimgnamesdict[subjnum]=list()\n",
    "        allimgnamesdict[subjnum].append(i)\n",
    "n_classes=len(allimgnamesdict)\n",
    "########################################################################################################################################\n",
    "\n",
    "train_set_names=list()\n",
    "train_set_labels=list()\n",
    "test_set_names=list()\n",
    "test_set_labels=list()\n",
    "\n",
    "for i in  allimgnamesdict:\n",
    "    random.shuffle(allimgnamesdict[i])\n",
    "    hm_test=int(0.2*len(allimgnamesdict[i]))#how many examples to take for the test set, here we use 20% of data for test and 80% for training\n",
    "    test_set_names=test_set_names+allimgnamesdict[i][0:hm_test]\n",
    "    test_set_labels=test_set_labels+[int(i)]*hm_test\n",
    "    train_set_names=train_set_names+allimgnamesdict[i][hm_test:]\n",
    "    train_set_labels=train_set_labels+[int(i)]*(len(allimgnamesdict[i])-hm_test)\n",
    "\n",
    "##################################################\n",
    "#shuffle the training and testing sets \n",
    "combinetrain=list(zip(train_set_names,train_set_labels))\n",
    "combinetest=list(zip(test_set_names,test_set_labels))\n",
    "\n",
    "random.shuffle(combinetrain)\n",
    "random.shuffle(combinetest)\n",
    "\n",
    "train_set_names[:],train_set_labels[:]=zip(*combinetrain)\n",
    "test_set_names[:],test_set_labels[:]=zip(*combinetest)\n",
    "##################################################\n",
    "\n",
    "'''\n",
    "print allimgtensor\n",
    "print type(allimgtensor)\n",
    "print allimglabels\n",
    "print type(allimaglabelstensor)\n",
    "'''\n",
    "\n",
    "testarray=np.zeros((len(test_set_names),imsize*imsize))\n",
    "testlabels=np.zeros((len(test_set_names),n_classes))\n",
    "counter=0\n",
    "for i in test_set_names:\n",
    "    testlabels[counter,int(test_set_names[counter][7:9])-1]=1#labels as one hot\n",
    "    im=Image.open(datadirectory+i)\n",
    "    im=im.resize((imsize,imsize),Image.NEAREST)\n",
    "    im=np.asarray(im)/255.0\n",
    "    testarray[counter,:]=im.reshape((imsize*imsize,))\n",
    "    counter+=1\n",
    "    '''\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "trainarray=np.zeros((len(train_set_names),imsize*imsize))\n",
    "trainlabels=np.zeros((len(train_set_labels),n_classes))\n",
    "counter=0\n",
    "for i in train_set_names:\n",
    "    trainlabels[counter,int(train_set_names[counter][7:9])-1]=1#labels as one hot\n",
    "    im=Image.open(datadirectory+i)\n",
    "    im=im.resize((imsize,imsize),Image.NEAREST)\n",
    "    im=np.asarray(im)/255.0\n",
    "    trainarray[counter,:]=im.reshape((imsize*imsize,))\n",
    "    counter+=1\n",
    "\n",
    "########################################################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = [(1.0,'max','Adam'),(0.8,'max','Adam'),(0.5,'max','Adam'),(1.0,'avg','Adam'),(0.8,'avg','Adam'),(0.5,'avg','Adam')]\n",
    "grid_search = [(0.5,'max','Adam')]\n",
    "for i in range(len(grid_search)):\n",
    "    x = tf.placeholder('float', [None, imsize*imsize])\n",
    "    y = tf.placeholder('float',[None,n_classes])\n",
    "    keep_rate = grid_search[i][0]\n",
    "    pool_method = grid_search[i][1]\n",
    "    optimizer_method = grid_search[i][2]\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    def train_neural_network(x):\n",
    "        if x == None:\n",
    "                print('problem')\n",
    "        def convolutional_neural_network(x):\n",
    "            weights = {'W_conv1':tf.Variable(tf.random_normal([5,5,1,32])),\n",
    "                       'W_conv2':tf.Variable(tf.random_normal([5,5,32,64])),\n",
    "                       'W_fc':tf.Variable(tf.random_normal([int(imsize/4)*int(imsize/4)*64,1024])),#imsize/4 because each max pool has a stride of 2, so it reduces dimensionality by 2 twice or 1/2^2\n",
    "                       'out':tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "            biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n",
    "                       'b_conv2':tf.Variable(tf.random_normal([64])),\n",
    "                       'b_fc':tf.Variable(tf.random_normal([1024])),\n",
    "                       'out':tf.Variable(tf.random_normal([n_classes]))}\n",
    "            x = tf.reshape(x, shape=[-1, imsize, imsize, 1])\n",
    "            conv1 = tf.nn.relu(conv2d(x, weights['W_conv1']) + biases['b_conv1'])\n",
    "            conv1 = pool2d(conv1,pool_method)\n",
    "\n",
    "            conv2 = tf.nn.relu(conv2d(conv1, weights['W_conv2']) + biases['b_conv2'])\n",
    "            conv2 = pool2d(conv2,pool_method)\n",
    "\n",
    "            fc = tf.reshape(conv2,[-1, int(imsize/4)*int(imsize/4)*64])#imsize/4 because each max pool has a stride of 2, so it reduces dimensionality by 2 twice or 1/2^2\n",
    "            fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n",
    "            fc = tf.nn.dropout(fc, keep_rate)\n",
    "\n",
    "            output = tf.matmul(fc, weights['out'])+biases['out']\n",
    "\n",
    "            return output\n",
    "    \n",
    "        def conv2d(x, W):\n",
    "            return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "        def pool2d(x,how):\n",
    "            if how == 'max':\n",
    "                return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "            return tf.nn.avg_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "#------------------------------------------------\n",
    "        optimizer = None\n",
    "        prediction = convolutional_neural_network(x)\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))\n",
    "        if optimizer_method == 'Adam':\n",
    "            optimizer = tf.train.AdamOptimizer().minimize(cost) #learning_rate=0.001\n",
    "        with tf.Session() as sess:\n",
    "            #sess.run(tf.initialize_all_variables())\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            acclist=list()\n",
    "            losslist=list()\n",
    "            for epoch in range(num_epochs):\n",
    "                epoch_loss = 0\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={x: trainarray, y: trainlabels})\n",
    "                epoch_loss += c\n",
    "                correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "                acclist.append(accuracy.eval({x:testarray, y:testlabels}))\n",
    "                losslist.append(epoch_loss)\n",
    "                if epoch%40 ==0:\n",
    "                    print('Epoch '+ str(epoch+1) + '/'+str(num_epochs)+','+' loss:'+str(epoch_loss),'Test Accuracy:',accuracy.eval({x:testarray, y:testlabels}))\n",
    "\n",
    "            correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "            print('Accuracy:',accuracy.eval({x:testarray, y:testlabels}))\n",
    "            return acclist,losslist\n",
    "        \n",
    "    acclist,losslist=train_neural_network(x)\n",
    "    \n",
    "    with open('accuracy_dropout_{}_{}pool_{}_large'.format(keep_rate,pool_method,optimizer_method), 'w') as f:\n",
    "        for item in acclist:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    with open('loss_dropout_{}_{}pool_{}_large'.format(keep_rate,pool_method,optimizer_method), 'w') as f:\n",
    "        for item in losslist:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(5), Dimension(5), Dimension(1), Dimension(32)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = {'W_conv1':tf.Variable(tf.random_normal([5,5,1,32])),\n",
    "                       'W_conv2':tf.Variable(tf.random_normal([5,5,32,64])),\n",
    "                       'W_fc':tf.Variable(tf.random_normal([int(imsize/4)*int(imsize/4)*64,1024])),#imsize/4 because each max pool has a stride of 2, so it reduces dimensionality by 2 twice or 1/2^2\n",
    "                       'out':tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "weights['W_conv1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(5), Dimension(5), Dimension(32), Dimension(64)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights['W_conv2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1024), Dimension(15)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights['out'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(1024)])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = {'W_conv1':tf.Variable(tf.random_normal([5,5,1,32])),\n",
    "                       'W_conv2':tf.Variable(tf.random_normal([5,5,32,64])),\n",
    "                       'W_fc':tf.Variable(tf.random_normal([int(imsize/4)*int(imsize/4)*64,1024])),#imsize/4 because each max pool has a stride of 2, so it reduces dimensionality by 2 twice or 1/2^2\n",
    "                       'out':tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n",
    "           'b_conv2':tf.Variable(tf.random_normal([64])),\n",
    "           'b_fc':tf.Variable(tf.random_normal([1024])),\n",
    "           'out':tf.Variable(tf.random_normal([n_classes]))}\n",
    "x = tf.reshape(x, shape=[-1, imsize, imsize, 1])\n",
    "conv1 = tf.nn.relu(conv2d(x, weights['W_conv1']) + biases['b_conv1'])\n",
    "conv1 = pool2d(conv1,pool_method)\n",
    "\n",
    "conv2 = tf.nn.relu(conv2d(conv1, weights['W_conv2']) + biases['b_conv2'])\n",
    "conv2 = pool2d(conv2,pool_method)\n",
    "\n",
    "fc = tf.reshape(conv2,[-1, int(imsize/4)*int(imsize/4)*64])#imsize/4 because each max pool has a stride of 2, so it reduces dimensionality by 2 twice or 1/2^2\n",
    "fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n",
    "fc = tf.nn.dropout(fc, keep_rate)\n",
    "\n",
    "fc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "            return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def pool2d(x,how):\n",
    "    if how == 'max':\n",
    "    #                        size of window         movement of window\n",
    "        return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    #if how == 'avg':\n",
    "    return tf.nn.avg_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "#------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
